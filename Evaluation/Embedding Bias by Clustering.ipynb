{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import numpy as np\n",
    "\n",
    "import preprocess\n",
    "import pandas as pd\n",
    "\n",
    "import data_v3\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import model as modelScript\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, 'r', encoding='utf-8-sig')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "seed = 20190328\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParameters(model):\n",
    "    # load vocab & file index  \n",
    "    if 'cda' in model:\n",
    "        path = 'processedDataCda/'\n",
    "        vocab = preprocess.read_vocab(os.path.join('data','VOCAB_cda.txt'))\n",
    "        idx_train = pd.read_json('data/idx_train_cda.json')\n",
    "        idx_val = pd.read_json('data/idx_val_cda.json')\n",
    "        idx_test = pd.read_json('data/idx_test_cda.json')\n",
    "    else:\n",
    "        path = 'processedData/'\n",
    "        vocab = preprocess.read_vocab(os.path.join('data','VOCAB.txt'))\n",
    "        idx_train = pd.read_json('data/idx_train.json')\n",
    "        idx_val = pd.read_json('data/idx_val.json')\n",
    "        idx_test = pd.read_json('data/idx_test.json')\n",
    "            \n",
    "    vocab.append('<eos>')\n",
    "    words2idx = {item : index for index, item in enumerate(vocab)}\n",
    "           \n",
    "    return path, vocab, words2idx, idx_train, idx_val, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterPerformanceEncoder(model,words,labels,verbose = False):\n",
    "    words_labels = [(w,l) for w,l in zip(words,labels) if w in corpus.words2idx ]\n",
    "    words = [w for w,l in words_labels]\n",
    "    labels = [l for w,l in words_labels]\n",
    "    word_indexes = torch.tensor([corpus.words2idx[w] for w in words]).to(device)\n",
    "    vectors = model.encoder(word_indexes)\n",
    "    vectors = vectors.cpu().detach().numpy()\n",
    "    print(vectors.shape)\n",
    "    accuracy = []\n",
    "    for i in range(20):\n",
    "        kmeans = KMeans(n_clusters=2)\n",
    "        kmeans.fit(vectors)\n",
    "        p = sum(kmeans.labels_ == labels)/ len(labels)\n",
    "        accuracy.append(max(p,1-p))\n",
    "    if verbose:\n",
    "        print(list(zip(words,kmeans.labels_)))\n",
    "    return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterPerformanceGlove(glove_vecs,words,labels,verbose = False):\n",
    "    words_labels = [(w,l) for w,l in zip(words,labels) if w in glove_vecs ]\n",
    "    words = [w for w,l in words_labels]\n",
    "    labels = [l for w,l in words_labels]\n",
    "    vectors = [glove_vecs[o] for o in words] \n",
    "    #print(vectors.shape)\n",
    "    accuracy = []\n",
    "    for i in range(20):\n",
    "        kmeans = KMeans(n_clusters=2)\n",
    "        kmeans.fit(vectors)\n",
    "        p = sum(kmeans.labels_ == labels)/ len(labels)\n",
    "        accuracy.append(max(p,1-p))\n",
    "    if verbose:\n",
    "        print(list(zip(words,kmeans.labels_)))\n",
    "    return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaleFile = '/home/urwa/Documents/Courses/NLU/GBLM/GBLM/Loss Function/gender_words/female_word_file.txt'\n",
    "maleFile = '/home/urwa/Documents/Courses/NLU/GBLM/GBLM/Loss Function/gender_words/male_word_file.txt'\n",
    "\n",
    "def getGenderIdx(femaleFile, maleFile, word2idx):\n",
    "    female_word_list = load_doc(femaleFile).split('\\n')\n",
    "    male_word_list = load_doc(maleFile).split('\\n')\n",
    "    #print(len(female_word_list),len(male_word_list))\n",
    "    pairs = [ (word2idx[f],word2idx[m]) for f,m in zip(female_word_list,male_word_list) \\\n",
    "             if f in word2idx and m in word2idx]\n",
    "    femaleIdx = [ f for f,m in pairs]\n",
    "    maleIdx = [ m for f,m in pairs]\n",
    "    #print(len(femaleIdx),len(maleIdx))\n",
    "    return femaleIdx,maleIdx\n",
    "\n",
    "def getGenderList(femaleFile, maleFile, word2idx):\n",
    "    female_word_list = load_doc(femaleFile).split('\\n')\n",
    "    male_word_list = load_doc(maleFile).split('\\n')\n",
    "    #print(len(female_word_list),len(male_word_list))\n",
    "    pairs = [ (f,m) for f,m in zip(female_word_list,male_word_list) \\\n",
    "             if f in word2idx and m in word2idx]\n",
    "    femaleIdx = [ f for f,m in pairs]\n",
    "    maleIdx = [ m for f,m in pairs]\n",
    "    #print(len(femaleIdx),len(maleIdx))\n",
    "    return femaleIdx,maleIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def load_glove(glove_file, n_vecs=20000):\n",
    "    \"\"\" \"\"\"\n",
    "    tok2vec = {}\n",
    "    with open(glove_file, 'r') as glove_fh:\n",
    "        for i, row in enumerate(glove_fh):\n",
    "            word, vec = row.split(' ', 1)\n",
    "            tok2vec[word] = np.array([float(n) for n in vec.split(' ')])\n",
    "            #if i >= n_vecs:\n",
    "            #    break\n",
    "    return tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleBiasWords = load_doc('maleBiasedWords.txt').split('\\n')\n",
    "len(maleBiasWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaleBiasWords = load_doc('femaleBiasedWords.txt').split('\\n')\n",
    "len(femaleBiasWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = femaleBiasWords + maleBiasWords\n",
    "labels = [0 for w in femaleBiasWords] + [1 for w in maleBiasWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"gnglove/1b-vectors300-0.8-0.8.txt\"\n",
    "glove_vecs = load_glove(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reg_0.5.pt',\n",
       " 'lambda_1_cda.pt',\n",
       " 'lambda_0.1.pt',\n",
       " 'lambda_0.5.pt',\n",
       " 'lambda_0.8.pt',\n",
       " 'lambda_1.pt',\n",
       " 'lambda_0.8_cda.pt',\n",
       " 'cda.pt',\n",
       " 'lambda_5.pt',\n",
       " 'lambda_0.1_cda.pt',\n",
       " 'lambda_10.pt',\n",
       " 'reg_0.1.pt',\n",
       " 'lambda_0.01.pt',\n",
       " 'lambda_8.pt',\n",
       " 'lambda_2.pt',\n",
       " 'lambda_0_baseline.pt',\n",
       " 'reg_0.8.pt',\n",
       " 'lambda_0.5_cda.pt',\n",
       " 'glove.pt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDir = './models/'\n",
    "modelFiles = [m for m in os.listdir(modelDir) if m.endswith('.pt')]\n",
    "modelFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFiles = ['cda.pt','glove.pt','lambda_0_baseline.pt','lambda_0.01.pt','lambda_0.1.pt','lambda_0.5.pt',\\\n",
    "              'lambda_0.8.pt',\\\n",
    "              'lambda_1.pt','lambda_2.pt','lambda_5.pt','lambda_8.pt','lambda_0.1_cda.pt','lambda_0.8_cda.pt',\\\n",
    "              'lambda_1_cda.pt','reg_0.1.pt','reg_0.5.pt','reg_0.8.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFiles = ['lambda_0.5_cda.pt','reg_0.1.pt','reg_0.5.pt','reg_0.8.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFiles = ['lambda_0','lambda_0.01','lambda_0.1','lambda_0.5','lambda_0.8','lambda_1','lambda_2','lambda_5','cda_lambda_0']\n",
    "embeddings = ['GnGlove'] + modelFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798846153846154\n"
     ]
    }
   ],
   "source": [
    "a = clusterPerformanceGlove(glove_vecs,words,labels,verbose = False)\n",
    "print(a)\n",
    "accuracy.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_0.5_cda.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/urwa/miniconda3/envs/NLUnew/lib/python3.7/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'model.RNNModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 300)\n",
      "0.6908212560386474\n",
      "reg_0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/urwa/miniconda3/envs/NLUnew/lib/python3.7/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'model.RNNModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-19e0de73c73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusterPerformanceEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8c1c74f6c96c>\u001b[0m in \u001b[0;36mclusterPerformanceEncoder\u001b[0;34m(model, words, labels, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "for m in modelFiles:\n",
    "    path, vocab, words2idx, idx_train, idx_val, idx_test = getParameters(m)\n",
    "    corpus = data_v3.Corpus(path, vocab, words2idx, idx_train, idx_val, idx_test)\n",
    "    ntokens = len(vocab)\n",
    "    save = modelDir + m  #+'.pt'\n",
    "    print(m)\n",
    "    with open(save, 'rb') as f:\n",
    "        model = torch.load(f).to(device)\n",
    "        model.rnn.flatten_parameters()\n",
    "        a = clusterPerformanceEncoder(model,words,labels,verbose = False)\n",
    "        print(a)\n",
    "        accuracy.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(embeddings, accuracy)\n",
    "_=plt.xticks(embeddings, rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = modelDir + modelFiles[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save, 'rb') as f:\n",
    "        model = torch.load(f)\n",
    "        # after load the rnn params are not a continuous chunk of memory\n",
    "        # this makes them a continuous chunk, and will speed up forward pass\n",
    "        model.rnn.flatten_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterPerformance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes = torch.tensor([corpus.dictionary.word2idx[w] for w in words]).to(device)\n",
    "male_indexes = torch.tensor([corpus.dictionary.word2idx[w] for w in MALE_NOUNS]).to(device)\n",
    "female_indexes = torch.tensor([corpus.dictionary.word2idx[w] for w in FEMALE_NOUNS]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    word_vectors = model.encoder(word_indexes)\n",
    "    male_vectors = model.encoder(male_indexes)\n",
    "    female_vectors = model.encoder(female_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def distance(v1,v2):\n",
    "    return torch.pow(torch.sum(torch.pow(v1-v2,2)),0.5).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_a_d = []\n",
    "f_a_d = []\n",
    "for w in  word_vectors:\n",
    "    m_d = []\n",
    "    for m in male_vectors:\n",
    "        m_d.append(distance(w,m))\n",
    "    m_a_d.append(sum(m_d)/len(m_d))\n",
    "    f_d = []\n",
    "    for f in female_vectors:\n",
    "        f_d.append(distance(w,f))\n",
    "    f_a_d.append(sum(f_d)/len(f_d))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.482090852269724"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaleMaleAvgDist = [m for m,l in zip(m_a_d,labels) if l == 0]\n",
    "femaleMaleAvgDist = sum(femaleMaleAvgDist) / len(femaleMaleAvgDist)\n",
    "femaleMaleAvgDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5359634490624297"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleMaleAvgDist = [m for m,l in zip(m_a_d,labels) if l == 1]\n",
    "maleMaleAvgDist = sum(maleMaleAvgDist) / len(maleMaleAvgDist)\n",
    "maleMaleAvgDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.307974853125873"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaleMaleAvgDist = [m for m,l in zip(m_a_d,labels) if l == 0]\n",
    "femaleMaleAvgDist = sum(femaleMaleAvgDist) / len(femaleMaleAvgDist)\n",
    "femaleMaleAvgDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.394133258812134"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleMaleAvgDist = [m for m,l in zip(m_a_d,labels) if l == 1]\n",
    "maleMaleAvgDist = sum(maleMaleAvgDist) / len(maleMaleAvgDist)\n",
    "maleMaleAvgDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
